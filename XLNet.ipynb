{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21bc9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eadc86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6843162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name                                     text_corrected  \\\n",
       "0   image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  image_2.jpeg  The best of #10 YearChallenge! Completed in le...   \n",
       "2   image_3.JPG  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3   image_4.png              10 Year Challenge - Sweet Dee Edition   \n",
       "4   image_5.png  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "  overall_sentiment  \n",
       "0          positive  \n",
       "1          positive  \n",
       "2          positive  \n",
       "3          positive  \n",
       "4           neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('memotion_dataset_7k/labels.csv')\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "df = df.drop(columns = ['text_ocr', 'humour', 'sarcasm', 'offensive', 'motivational'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25b24a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         False\n",
       "sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_text = pd.DataFrame()\n",
    "meme_text['text'] = df.text_corrected\n",
    "meme_text['sentiment'] = df.overall_sentiment\n",
    "meme_text.head()\n",
    "cleaned = meme_text.copy()\n",
    "cleaned.dropna(inplace=True)\n",
    "cleaned.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f9d4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...  positive\n",
       "1  The best of #10 YearChallenge! Completed in le...  positive\n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...  positive\n",
       "3              10 Year Challenge - Sweet Dee Edition  positive\n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   neutral"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7fbd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFXLNetModel, XLNetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ffd115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_model = 'xlnet-large-cased'\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2791c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xlnet(mname):\n",
    "    \"\"\" Creates the model. It is composed of the XLNet main block and then\n",
    "    a classification head its added\n",
    "    \"\"\"\n",
    "    # Define token ids as inputs\n",
    "    word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32')\n",
    "\n",
    "    # Call XLNet model\n",
    "    xlnet = TFXLNetModel.from_pretrained(mname)\n",
    "    xlnet_encodings = xlnet(word_inputs)[0]\n",
    "\n",
    "    # CLASSIFICATION HEAD \n",
    "    # Collect last step from last hidden state (CLS)\n",
    "    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n",
    "    # Apply dropout for regularization\n",
    "    doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n",
    "    # Final output \n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(doc_encoding)\n",
    "\n",
    "    # Compile model\n",
    "    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet = create_xlnet(xlnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22670412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "word_inputs (InputLayer)     [(None, 120)]             0         \n",
      "_________________________________________________________________\n",
      "tfxl_net_model (TFXLNetModel TFXLNetModelOutput(last_h 360268800 \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLa (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "outputs (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 360,273,925\n",
      "Trainable params: 360,273,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xlnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbc3cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = cleaned['text']\n",
    "Y = pd.get_dummies(cleaned['sentiment']).values\n",
    "#labels = cleaned['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0f4945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5240,), (5240, 5))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef68e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(tweets, tokenizer, max_len=120):\n",
    "    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n",
    "    inps = [tokenizer.encode_plus(t, max_length=max_len, pad_to_max_length=True, add_special_tokens=True) for t in tweets]\n",
    "    inp_tok = np.array([a['input_ids'] for a in inps])\n",
    "    ids = np.array([a['attention_mask'] for a in inps])\n",
    "    segments = np.array([a['token_type_ids'] for a in inps])\n",
    "    return inp_tok, ids, segments\n",
    "\n",
    "def warmup(epoch, lr):\n",
    "    \"\"\"Used for increasing the learning rate slowly, this tends to achieve better convergence.\n",
    "    However, as we are finetuning for few epoch it's not crucial.\n",
    "    \"\"\"\n",
    "    return max(lr +1e-6, 2e-5)\n",
    "\n",
    "def plot_metrics(pred, true_labels):\n",
    "    \"\"\"Plots a ROC curve with the accuracy and the AUC\"\"\"\n",
    "    acc = accuracy_score(true_labels, np.array(pred.flatten() >= .5, dtype='int'))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred)\n",
    "    auc = roc_auc_score(true_labels, pred)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, color='red')\n",
    "    ax.plot([0,1], [0,1], color='black', linestyle='--')\n",
    "    ax.set_title(f\"AUC: {auc}\\nACC: {acc}\");\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2234b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2198: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inp_tok, ids, segments = get_inputs(X_train, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af72bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, min_delta=0.02, restore_best_weights=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab54a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._12/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._12/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._13/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._13/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._14/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._14/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._15/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._15/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._16/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._16/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._17/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._17/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._18/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._18/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._19/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._19/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._20/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._20/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._21/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._21/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._22/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._22/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._23/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._23/rel_attn/seg_embed:0'] when minimizing the loss.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:799 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:530 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:636 apply_gradients\n        self._create_all_weights(var_list)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:823 _create_all_weights\n        self._create_slots(var_list)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adam.py:124 _create_slots\n        self.add_slot(var, 'm')\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:909 add_slot\n        weight = tf_variables.Variable(\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:262 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:244 _variable_v2_call\n        return previous_getter(\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3523 creator\n        return next_creator(**kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3523 creator\n        return next_creator(**kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3523 creator\n        return next_creator(**kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:750 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:264 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:293 __init__\n        initial_value = initial_value()\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py:151 __call__\n        return array_ops.zeros(shape, dtype)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2911 wrapped\n        tensor = fun(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2972 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:239 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3367 fill\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6897 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[1024,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b716463d2fed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minp_tok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: in user code:\n\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:799 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:530 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:636 apply_gradients\n        self._create_all_weights(var_list)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:823 _create_all_weights\n        self._create_slots(var_list)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adam.py:124 _create_slots\n        self.add_slot(var, 'm')\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:909 add_slot\n        weight = tf_variables.Variable(\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:262 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:244 _variable_v2_call\n        return previous_getter(\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3523 creator\n        return next_creator(**kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3523 creator\n        return next_creator(**kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3523 creator\n        return next_creator(**kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:750 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:264 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:293 __init__\n        initial_value = initial_value()\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py:151 __call__\n        return array_ops.zeros(shape, dtype)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2911 wrapped\n        tensor = fun(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2972 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:239 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3367 fill\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\hp\\anaconda3\\envs\\Rohit\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6897 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[1024,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n"
     ]
    }
   ],
   "source": [
    "hist = xlnet.fit(x=inp_tok, y=y_train, epochs=1, batch_size=4, validation_split=.15, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801d529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
